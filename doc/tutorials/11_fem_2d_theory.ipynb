{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da33693",
   "metadata": {},
   "source": [
    "# 2D FEM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fd66d",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf68de",
   "metadata": {},
   "source": [
    "The framework is designed to accompany these features:\n",
    "- MPI-based domain decomposition\n",
    "- parallelized, iterative solver that connects seamlessly\n",
    "- elastic deformation via fft-based convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895e197",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./figures/2D_FEM_Framework.png\" \n",
    "       alt=\"2D FEM framework\" \n",
    "       width=\"1000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## FEM Grid and Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0158be86",
   "metadata": {},
   "source": [
    "### Basis Element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7c68e",
   "metadata": {},
   "source": [
    "We use triangular basis elements with three quadrature points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71498f5a",
   "metadata": {},
   "source": [
    "```python\n",
    "# Barycentric coordinates for 3-point Gauss quadrature on triangle\n",
    "# each row is one quad point, columns are barycentric coords for nodes 0,1,2\n",
    "BARY_COORDS = np.array([\n",
    "    [2 / 3, 1 / 6, 1 / 6],\n",
    "    [1 / 6, 2 / 3, 1 / 6],\n",
    "    [1 / 6, 1 / 6, 2 / 3],\n",
    "])\n",
    "\n",
    "# Quadrature weights; sum up to 0.5 for one triangle\n",
    "WEIGHTS = np.array([1 / 6, 1 / 6, 1 / 6])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bcc49",
   "metadata": {},
   "source": [
    "Note that each square spanned by four grid points hold two elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c61430",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./figures/2D_FEM_point_names.png\"\n",
    "       alt=\"2D FEM point names\"\n",
    "       width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fdc6b",
   "metadata": {},
   "source": [
    "Effectively, we get a 7-point stencil. The test function of one point interacts with trial functions of 6 neighbouring points and itself.\n",
    "\n",
    "Note that point (0,0) does not interact with (1,1) and (-1,-1) due to the selected orientation of the triangles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88177c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./figures/2D_FEM_Stencil.png\" \n",
    "       alt=\"2D FEM Stencil\" \n",
    "       width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Grid Layout\n",
    "\n",
    "The 2D grid uses column-major ordering with shape `(Nx_padded, Ny_padded)`.\n",
    "\n",
    "- Axis 0 = X (West → East)\n",
    "- Axis 1 = Y (South → North)\n",
    "- Access: `field[x, y]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42720564",
   "metadata": {},
   "source": [
    "In FEM we need to go through all points of the domain and capture all dependencies of the point w.r.t. neighbouring points.\n",
    "\n",
    "To do this in a systematic way, we iterate through the squares spanned by the points. Each square has the similar structure, which allows vectorization.\n",
    "\n",
    "As a first step, we need to know how to map from `square i,j` $\\rightarrow$ point indices of `(bl, br, tl, tr)`.\n",
    "Then we can capture interactions within the left `(bl, br, tl)` and right `(br, tl, tr)` triangle.\n",
    "\n",
    "The figure below illustrates the mapping. Note that in the actual implementation, we use pre-computed mappings that are more complex but work on the similar idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4oegrxavb",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./figures/2D_FEM_pixels_points.png\" \n",
    "       alt=\"2D FEM pixels and points\" \n",
    "       width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Domain Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006100b",
   "metadata": {},
   "source": [
    "Domain decomposition is implemented using the `CartesianDecomposition` feature of [muGrid](https://github.com/muSpectre/muGrid). The following sections shortly address the domain decomposition functionality of muGrid, how boundary conditions are treated, and how grid indexing is implemented in order to correctly assemble a global equation system from the local parts of the decomposed domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5480f7",
   "metadata": {},
   "source": [
    "### muGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec9cff",
   "metadata": {},
   "source": [
    "muGrid offers a <code style=\"color:#c586c0\">CartesianDecomposition</code> object that requires an MPI communicator, grid size, number of ghost cells in all directions, and shape of subdivision.\n",
    "\n",
    "```python\n",
    "decomp = CartesianDecomposition(...)\n",
    "```\n",
    "<br>\n",
    "\n",
    "In our case, the subdivision is set to\n",
    "\n",
    "```python\n",
    "nb_subdivisions = (1, comm.size)\n",
    "```\n",
    "<br>\n",
    "\n",
    "meaning that each process owns a slice with \n",
    "- full x-length and \n",
    "- part of the y-range.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now fields can be instanciated \"under\" the decomposition object. When using these fields, each process will only see its own slice of the field.\n",
    "\n",
    "```python\n",
    "field = decomp.real_field('solution)\n",
    "```\n",
    "<br>\n",
    "\n",
    "Interface to fields:\n",
    "- `field.p` accesses the inner field\n",
    "- `field.pg` accesses the padded field with ghost cells\n",
    "- Writing needs to be done using the slicing operator `field.p[:] = arr`\n",
    "\n",
    "<br>\n",
    "\n",
    "Ghost cells either represent adjacent domains or periodic wrap-around. After the inner field is updated, ghost cells need to be separately updated using:\n",
    "\n",
    "```python\n",
    "decomp.communicate_ghosts(field)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881855c",
   "metadata": {},
   "source": [
    "### Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05454556",
   "metadata": {},
   "source": [
    "To take advantage of the muGrid-based framework, we use ghost cells as a means to impose boundary conditions. Thereby, we do not require injecting boundary conditions into the equation system during assembly.\n",
    "\n",
    "- <code style=\"color:#4CAF50\">Dirichlet BC</code>: Boundary values are directly written to ghost cells. This is slightly different to the current explicit solver, where we demand the BC value to be satisfied **between** the last inner node and the ghost cell\n",
    "- <code style=\"color:#4CAF50\">Neumann BC</code>: The ghost cell value is calculated using information from only the direct neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e25dbd",
   "metadata": {},
   "source": [
    "### Local vs. Global Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b9f09",
   "metadata": {},
   "source": [
    "The challenge of the parallelized approach is to correctly join the local equations systems into a global system. Therefore, each process has to know where its slice is positioned in the global domain. The basis of this translation is given by index masks.\n",
    "\n",
    "Assume we have a `(3,4)` domain and run on two processes. Each process then has a `(3,2)` sub-domain (and a `(5,4)` padded domain that includes ghost cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9ee12",
   "metadata": {},
   "source": [
    "<code style=\"color:#c586c0\">Global Domain Indexing</code>:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\begin{array}{cc:cc}\n",
    "0 & 3 & 6 & 9 \\\\\n",
    "1 & 4 & 7 & 10 \\\\\n",
    "2 & 5 & 8 & 11\n",
    "\\end{array}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226a5d4",
   "metadata": {},
   "source": [
    "<code style=\"color:#4CAF50\">Process 1</code>:\n",
    "\n",
    "$$\n",
    "\\mathrm{Local \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 3 \\\\\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "\\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\mathrm{Global \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 3 \\\\\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f779c54",
   "metadata": {},
   "source": [
    "<code style=\"color:#4CAF50\">Process 2</code>:\n",
    "\n",
    "$$\n",
    "\\mathrm{Local \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 3 \\\\\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "\\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\mathrm{Global \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "6 & 9 \\\\\n",
    "7 & 10 \\\\\n",
    "8 & 11 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b25776",
   "metadata": {},
   "source": [
    "Note that it gets a little more complex since e.g. on process 1, the points 3,4,5 interact with (global) points 6,7,8 of process 2 (and if periodic in y, the points 0,1,2 interact with 9,10,11). Therefore, each process also has to know global indices of its ghost cells. See example for process 2 below. \n",
    "\n",
    "The `-1` stands for Dirichlet boundary condition. In case of Neumann boundary condition, the index of the neighbouring point has to be \"forwarded\" to the ghost point to correctly capture its influence. Since Dirichlet/Neumann is variable-specific (for example Dirichlet for density but Neumann for flux) these index-masks need to be determined and used variable-specific.\n",
    "\n",
    "For simplicity, we assume Dirichlet BCs on all sides. Note that regarding the indexing, inner nodes are filled first, followed by ghost cells that are not Dirichlet-type boundaries. This has to do with the fact that on each rank, only the residuals of the inner points are evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1907a",
   "metadata": {},
   "source": [
    "<code style=\"color:#4CAF50\">Process 2</code>:\n",
    "\n",
    "$$\n",
    "\\mathrm{Local \\, padded \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "-1 & -1 & -1 & -1 \\\\\n",
    "6 &  0 &  3 & -1 \\\\\n",
    "7 &  1 &  4 & -1 \\\\\n",
    "8 &  2 &  5 & -1 \\\\\n",
    "-1 & -1 & -1 & -1\n",
    "\\end{pmatrix}\n",
    "\\quad\\quad\n",
    "\\mathrm{Global \\, padded \\, indices:} \\quad\n",
    "\\begin{pmatrix}\n",
    "-1 & -1 & -1 & -1 \\\\\n",
    "3 &  6 &  9 & -1 \\\\\n",
    "4 &  7 &  10 & -1 \\\\\n",
    "5 &  8 &  11 & -1 \\\\\n",
    "-1 & -1 & -1 & -1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b9815",
   "metadata": {},
   "source": [
    "## Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b86d64e",
   "metadata": {},
   "source": [
    "The equation system yields a sparse tangential matrix. Note that storing the full matrix is not performant and quickly reaches memory bottleneck.\n",
    "\n",
    "> Example: <br> 128x128 grid $\\rightarrow$ 16.384 points, with four equations per point $\\rightarrow$ 65.536 equations $\\rightarrow$ 65.536^2 = 4.3x10^9 floats in the tangential matrix $\\approx$ 32 GB memory\n",
    "\n",
    "However, the number of non-zeros (nnz) is - with our stencil - at maximum 7x4 = 28 per equation (residual is influenced by this number of variables). For performant assembly and for consistency with `petsc`, we use `COO` (Coordinate List) for efficiently capturing only nnz values.\n",
    "\n",
    "Assume you want to represent this matrix in `COO` format:\n",
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "10 & 0 & 0 \\\\\n",
    "0 & 0 & 20 \\\\\n",
    "0 & 30 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "```python\n",
    "row = [0, 1, 2]\n",
    "col = [0, 2, 1]\n",
    "values = [10, 20, 30]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5e931",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2afc6",
   "metadata": {},
   "source": [
    "**Block vs. Point-interleaved ordering**\n",
    "\n",
    "This is an important concept in order to understand the implementation approach.\n",
    "\n",
    "During assembly, we iterate through the individual terms the residuals consist of. And for each term, we iterate through dependent variables.\n",
    "\n",
    "> Example: <br> The mass conservation residual contains the $- \\frac{\\partial j_x}{\\partial x}$ term. There is only one dependent variable: $j_x$.\n",
    "\n",
    "The point is that each step consists of determining the change of `residual X` due to `variable Y`. So a block is represented by an `X-Y` combination.\n",
    "\n",
    "And since we evaluate $\\sim$ 40 of these blocks in each assembly, it is performant to let each block be represented by a contiguous piece on the `COO` list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebc61d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ec028",
   "metadata": {},
   "source": [
    "The second part of the story is the relation between the local and the global equation system.\n",
    "\n",
    "We want the equations of the local equation system (tangential matrix of the process-specific subdomain) to be placed on a contiguos piece of the global equation system.\n",
    "\n",
    "For this, we need point-interleaved ordering of the system.\n",
    "\n",
    "Here is an illustration assuming a small `(2,2)` system with two residuals/equations `r1`, `r2` and two variables/fields `v1`, `v2`. It is decomposed on two processes with `(2,1)` subdomains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c240e8",
   "metadata": {},
   "source": [
    "<code style=\"color:#4CAF50\">Process 1</code> owns the points `[0, 1]` and the residuals and variables that live on them.\n",
    "\n",
    "These are the residuals (rows) $\\color{ForestGreen}{0\\text{--}r_1, 0\\text{--}r_2}, 1\\text{--}r_1, 1\\text{--}r_2$ and variables (column) $\\color{ForestGreen}{0\\text{--}v_1, 0\\text{--}v_2}, 1\\text{--}v_1, 1\\text{--}v_2$. Convention here: #point-var/residual\n",
    "\n",
    "If the global matrix used **block format**, the content of process 1 would be scattered across it:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccccccc}\n",
    " &\n",
    " 0\\text{--}v_1 & 1\\text{--}v_1 & 2\\text{--}v_1 & 3\\text{--}v_1 &\n",
    " 0\\text{--}v_2 & 1\\text{--}v_2 & 2\\text{--}v_2 & 3\\text{--}v_2\n",
    "\\\\ \\hline\n",
    "\n",
    "0\\text{--}r_1 &\n",
    "\\color{green}{*} & \\color{green}{*} & * & * &\n",
    "\\color{green}{*} & \\color{green}{*} & * & *\n",
    "\\\\\n",
    "\n",
    "1\\text{--}r_1 &\n",
    "\\color{green}{*} & \\color{green}{*} & * & * &\n",
    "\\color{green}{*} & \\color{green}{*} & * & *\n",
    "\\\\\n",
    "\n",
    "2\\text{--}r_1 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "3\\text{--}r_1 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "0\\text{--}r_2 &\n",
    "\\color{green}{*} & \\color{green}{*} & * & * &\n",
    "\\color{green}{*} & \\color{green}{*} & * & *\n",
    "\\\\\n",
    "\n",
    "1\\text{--}r_2 &\n",
    "\\color{green}{*} & \\color{green}{*} & * & * &\n",
    "\\color{green}{*} & \\color{green}{*} & * & *\n",
    "\\\\\n",
    "\n",
    "2\\text{--}r_2 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "3\\text{--}r_2 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "But using **point-interleaved ordering**, process 1 is represented by a contiguous block in the global matrix:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccccccc}\n",
    " &\n",
    " 0\\text{--}v_1 & 0\\text{--}v_2 & 1\\text{--}v_1 & 1\\text{--}v_2 &\n",
    " 2\\text{--}v_1 & 2\\text{--}v_2 & 3\\text{--}v_1 & 3\\text{--}v_2\n",
    "\\\\ \\hline\n",
    "\n",
    "0\\text{--}r_1 &\n",
    "\\color{green}{*} & \\color{green}{*} & \\color{green}{*} & \\color{green}{*} & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "0\\text{--}r_2 &\n",
    "\\color{green}{*} & \\color{green}{*} & \\color{green}{*} & \\color{green}{*} & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "1\\text{--}r_1 &\n",
    "\\color{green}{*} & \\color{green}{*} & \\color{green}{*} & \\color{green}{*} & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "1\\text{--}r_2 &\n",
    "\\color{green}{*} & \\color{green}{*} & \\color{green}{*} & \\color{green}{*} & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "2\\text{--}r_1 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "2\\text{--}r_2 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "3\\text{--}r_1 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\\\\n",
    "\n",
    "3\\text{--}r_2 &\n",
    "* & * & * & * & * & * & * & *\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12579b22",
   "metadata": {},
   "source": [
    "> Therefore, a translation is necessary from block to point-interleaved ordering.\n",
    "\n",
    "This is implemented by using two `COO` lists. The `values` array is the same for both.\n",
    "\n",
    "- `local_rows`, `local_cols` - used during block-wise iteration for assembly (one block is a contiguous piece on the `values` array)\n",
    "- `global_rows`, `global_cols` - translation to global equation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290739c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9d5a0",
   "metadata": {},
   "source": [
    "**Overview of important containers**\n",
    "\n",
    "All index mappings are computed once during setup and are stored in these containers:\n",
    "\n",
    "```\n",
    "FEMAssemblyLayout        top-level container\n",
    "├── MatrixCOOPattern     COO local and global indices\n",
    "├── RHSPattern           RHS vector indices\n",
    "├── ScalingInfo          diagonal scaling factors\n",
    "└── jacobian_terms       holds term/variable specific indices and precomputed values\n",
    "```\n",
    "\n",
    "Note that similar containers exist for the rhs, but details are left out here.\n",
    "\n",
    "<code style=\"color:#c586c0\">TermKey</code> is a combination of term and dependent variable.\n",
    "\n",
    "<br>\n",
    "\n",
    "**MatrixCOOPattern**\n",
    "\n",
    "Stores the sparse matrix structure in COO (Coordinate) format.\n",
    "\n",
    "The `MatrixCOOPattern` lists are determined first, and `JacobianTermMap`s are then created based on them.\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `local_rows` | IntArray | Local row indices for each COO entry |\n",
    "| `local_cols` | IntArray | Local column indices for each COO entry |\n",
    "| `global_rows` | IntArray | Global row indices (for PETSc/MPI) |\n",
    "| `global_cols` | IntArray | Global column indices (for PETSc/MPI) |\n",
    "| `res_block_idx` | Int8Array | Residual block index (0=mass, 1=mom_x, ...) |\n",
    "| `var_block_idx` | Int8Array | Variable block index (0=ρ, 1=jx, ...) |\n",
    "\n",
    "The block indices enable per-variable scaling without recomputing the COO structure.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225af28",
   "metadata": {},
   "source": [
    "**JacobianTermMap** - for each <code style=\"color:#c586c0\">TermKey</code>\n",
    "\n",
    "Maps contributions from one block (term-variable) to matrix entries.\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `coo_idx` | IntArray | Which COO entries receive contributions |\n",
    "| `weights` | NDArray | precomputed integration weights |\n",
    "| `sq_x`, `sq_y` | IntArray | Square indices for field value lookup |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9785c0",
   "metadata": {},
   "source": [
    "**FEMAssemblyLayout**\n",
    "\n",
    "Top-level container that holds everything.\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `matrix_coo` | MatrixCOOPattern | Sparse matrix structure |\n",
    "| `rhs` | RHSPattern | RHS vector structure |\n",
    "| `jacobian_terms` | dict | Maps <code style=\"color:#c586c0\">TermKey</code> → `JacobianTermMap` |\n",
    "\n",
    "The `get_petsc_info()` method extracts PETSc-specific assembly info, and `build_scaling()` constructs diagonal scaling factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88i18lv406c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j54xerf1q2",
   "metadata": {},
   "source": [
    "### Diagonal Scaling\n",
    "\n",
    "Variables in the system span different magnitudes (e.g., ρ~10³ kg/m³, E~10⁸ J/m³), leading to an ill-conditioned Jacobian. Diagonal scaling improves conditioning without modifying the physics.\n",
    "\n",
    "**Transformation**\n",
    "\n",
    "The linear system $J \\cdot \\delta q = -R$ is transformed to:\n",
    "\n",
    "$$\n",
    "J^* \\cdot \\delta q^* = -R^*\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $D_q = \\text{diag}(q_\\text{scale})$ — variable scaling (characteristic magnitudes)\n",
    "- $D_R = \\text{diag}(R_\\text{scale})$ — residual scaling (same as $D_q$ by convention)\n",
    "- $J^* = D_R^{-1} \\cdot J \\cdot D_q$\n",
    "- $R^* = D_R^{-1} \\cdot R$\n",
    "- $\\delta q = D_q \\cdot \\delta q^*$\n",
    "\n",
    "<br>\n",
    "\n",
    "**ScalingInfo**\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `coo_scale` | NDArray | Per-entry scaling for COO values: $1/(R_\\text{scale} \\cdot q_\\text{scale})$ |\n",
    "| `rhs_scale` | NDArray | Per-DOF residual scaling |\n",
    "| `sol_scale` | NDArray | Per-DOF solution unscaling |\n",
    "| `char_scales` | dict | Characteristic scales: `{'rho': ..., 'jx': ..., 'jy': ..., 'E': ...}` |\n",
    "\n",
    "Characteristic scales are derived from the problem specification:\n",
    "- $\\rho_\\text{ref}$ from `rho0`\n",
    "- $j_\\text{ref} = \\rho_\\text{ref} \\cdot \\max(|U|, |V|)$\n",
    "- $E_\\text{ref} = \\rho_\\text{ref} \\cdot c_v \\cdot T_\\text{ref}$ (if energy equation active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21590b3f",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1709eef",
   "metadata": {},
   "source": [
    "For parallelized solving of the equation system, we use `PETSc` since it provides efficient, scalable solvers and preconditioners for large sparse systems on parallel architectures.\n",
    "\n",
    "The following container holds all information that is exposed to `PETScSystem`, which wraps the `PETSc` functionality.\n",
    "\n",
    "**PETScAssemblyInfo**\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `local_size` | Int | Number of equations in the local system |\n",
    "| `global_size` | Int | Number of equations in the global system |\n",
    "| `mat_global_rows` | IntArray | Global `COO` indices |\n",
    "| `mat_global_cols` | IntArray | Global `COO` indices |\n",
    "| `rhs_global_rows` | IntArray | RHS indices |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2327e",
   "metadata": {},
   "source": [
    "Important lines for translation of local assembly to global system within `PETScSystem` are:\n",
    "\n",
    "```python\n",
    "class PETScSystem:\n",
    "\n",
    "    def _create_petsc_objects(self):\n",
    "        self.mat = PETSc.Mat().create(self.comm)  # create matrix\n",
    "        self.mat.setSizes([(local_size, global_size), (local_size, global_size)])  # set local and global sizes (decomposition information)\n",
    "        self.mat.setPreallocationCOO(info.mat_global_rows, info.mat_global_cols)  # provide COO information\n",
    "\n",
    "    def assemble(self, coo_values: NDArray):\n",
    "        self.mat.setValuesCOO(coo_values, PETSc.InsertMode.INSERT_VALUES) # set values using COO information\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757bead",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f0680",
   "metadata": {},
   "source": [
    "**`PETSc` alternative for serial execution**\n",
    "\n",
    "When PETSc is unavailable, `ScipySystem` provides a serial fallback using SciPy's sparse direct solver (`splu`). Note that this fallback is automatically activated in serial execution when `PETSc` is not available. When running in parallel without `PETSc`, an error is raised.\n",
    "\n",
    "```python\n",
    "class ScipySystem:\n",
    "    def assemble(self, coo_values, R_local):\n",
    "        self.mat = csr_matrix((coo_values, (rows, cols)), shape=(n, n))\n",
    "        self.rhs = -R_local\n",
    "\n",
    "    def solve(self, ...):\n",
    "        return splu(self.mat).solve(self.rhs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8d35d",
   "metadata": {},
   "source": [
    "## Elastic Deformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc86ba7",
   "metadata": {},
   "source": [
    "Elastic deformation is computed using the Green's function based approach, where the required convolution operation can be efficiently conducted in Fourier space see [Elastic Deformation Tutorial](07_elastic_deformation.ipynb).\n",
    "\n",
    "We use the <code style=\"color:#c586c0\">muGrid.FFTEngine</code> to handle parallelized FFT operations. The `FFTEngine` acts as a wrapper similar to `CartesianDecomposition` and offers `fft` and `ifft` operations. \n",
    "\n",
    "Note that we set the subdivision of `CartesianDecomposition` to match the non-customizable subdivision of `FFTEngine`.\n",
    "In parallelized runs, we can therefore directly use the local pressure fields in `CartesianDecomposition` as input for fft operations.\n",
    "\n",
    "Unfortunately however, this is only true for fully periodic domains. For semi-periodic or fully non-periodic domains, the fft approach for elastic deformation requires a decoupling trick, which in turn requires padding the domain from $N_x, N_y \\rightarrow 2 N_x, 2 N_y$. In this case, the local data needs to be massively redistributed (compare figure below).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd062b4a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./figures/FFTDomainTranslation.png\" \n",
    "       alt=\"2D FEM framework\" \n",
    "       width=500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbec52f",
   "metadata": {},
   "source": [
    "This redistribution is handled by the <code style=\"color:#c586c0\">FFTDomainDecomposition</code> wrapper.\n",
    "Here is a small overview of the most important lines. \n",
    "\n",
    "Note that when simulating a fully periodic domain, the exchange plan is basically a 1:1 copy of local fields.\n",
    "\n",
    "```python\n",
    "class FFTDomainTranslation:\n",
    "    def __init__(self, ...):\n",
    "        self._compute_fft_grid_size()  # compute FFT grid size based on periodicity\n",
    "        self.fft_engine = muGrid.FFTEngine([self.Nx_fft, self.Ny_fft], comm)  # create FFTEngine with computed size\n",
    "        self._build_exchange_plan()  # core: build exchange plan for MPI redistribution\n",
    "\n",
    "    def embed(self, src: np.ndarray, dst: np.ndarray):\n",
    "        # CartesianDecomposition -> FFTDeomposition\n",
    "\n",
    "    def extract(self, src: np.ndarray, dst: np.ndarray):\n",
    "        # FFTDecomposition -> CartesianDecomposition\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8c44a",
   "metadata": {},
   "source": [
    "When computing displacement from elastic deformation, the wrapper functions of <code style=\"color:#c586c0\">FFTDomainDecomposition</code> are used as follows:\n",
    "\n",
    "```python\n",
    "class ElasticDeformation:\n",
    "    def get_deformation(self, p: NDArray)\n",
    "    \n",
    "        # redistribute pressure field on padded domain\n",
    "        self.fft_translation.embed(p, p_padded_domain)\n",
    "\n",
    "        # calculate force and get displacement via fft (on padded domain)\n",
    "        force_padded_domain = self.area_per_cell * p_padded_domain\n",
    "        disp_padded_domain = - self.ElDef.evaluate_disp(force_padded_domain)\n",
    "\n",
    "        # collect displacement field from padded domain\n",
    "        self.fft_translation.extract(disp_padded_domain, displacement)\n",
    "    \n",
    "        return displacement  # displacement on local CartesianDecomposition field\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b340ef",
   "metadata": {},
   "source": [
    "## Implementation Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366eedc0",
   "metadata": {},
   "source": [
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `solver_fem_2d.py` | Main 2D FEM solver: Newton iteration, assembly dispatch, time-stepping |\n",
    "| `fem_2d/elements.py` | <code style=\"color:#c586c0\">TriangleQuadrature</code> - shape functions, derivatives, interpolation operators |\n",
    "| `fem_2d/terms.py` | <code style=\"color:#c586c0\">NonLinearTerm</code>, `get_active_terms()`, residual terms (`R11x`, `R11y`, ...) |\n",
    "| `fem_2d/assembly_layout.py` | <code style=\"color:#c586c0\">FEMAssemblyLayout</code>, <code style=\"color:#c586c0\">MatrixCOOPattern</code>, <code style=\"color:#c586c0\">RHSPattern</code>, <code style=\"color:#c586c0\">ScalingInfo</code>, <code style=\"color:#c586c0\">JacobianTermMap</code>, <br> <code style=\"color:#c586c0\">PETScAssemblyInfo</code> - precomputed indexing, local-global translation, scaling, and weightings |\n",
    "| `fem_2d/grid_index.py` | <code style=\"color:#c586c0\">GridIndexManager</code> - local/global index masks, BC handling, stencil connectivity |\n",
    "| `fem_2d/quad_fields.py` | <code style=\"color:#c586c0\">QuadFieldManager</code> - field storage, nodal→quadrature interpolation |\n",
    "| `fem_2d/petsc_system.py` | <code style=\"color:#c586c0\">PETScSystem</code> - distributed matrix assembly and KSP linear solve (parallel/serial) |\n",
    "| `fem_2d/scipy_system.py` | <code style=\"color:#c586c0\">ScipySystem</code> - serial sparse solver fallback when PETSc unavailable |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbdbf2",
   "metadata": {},
   "source": [
    "# 2D Equations\n",
    "\n",
    "Overview of 2D equations solved by the FEM framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57681c4",
   "metadata": {},
   "source": [
    "## Mass Conservation\n",
    "\n",
    "Mass conservation connects density $\\rho$ and mass fluxes $j_x$, $j_y$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 &= \n",
    "-\\,\\frac{\\overline{\\rho} - \\overline{\\rho}_{\\mathrm{prev}}}{\\Delta t} \\\\[4pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial \\overline{j_x}}{\\partial x}\n",
    "- \\frac{1}{h}\\,\\frac{\\partial h}{\\partial x}\\,\\overline{j_x} \\\\[4pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial \\overline{j_y}}{\\partial y}\n",
    "- \\frac{1}{h}\\,\\frac{\\partial h}{\\partial y}\\,\\overline{j_y} \\\\[4pt]\n",
    "&\\quad\n",
    "-\\,\\overline{\\rho}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial t} \\\\[4pt]\n",
    "&\\quad\n",
    "-\\,\\alpha_p \\left( \\frac{\\partial^2 p}{\\partial x^2} + \\frac{\\partial^2 p}{\\partial y^2} \\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i0p31l0xx4",
   "metadata": {},
   "source": [
    "- **R1T**: Time derivative\n",
    "- **R11x**: Flux divergence in x\n",
    "- **R11Sx**: Flux divergence height source in x\n",
    "- **R11y**: Flux divergence in y\n",
    "- **R11Sy**: Flux divergence height source in y\n",
    "- **R12**: Height change over time (not implemented)\n",
    "- **R1Stabx**, **R1Staby**: Pressure stabilization (Brezzi-Pitkäranta style for equal-order elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ybcs41qdxs9",
   "metadata": {},
   "source": [
    "## Momentum x\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 &= \n",
    "- \\frac{\\overline{j_x} - \\overline{j_x}_{\\mathrm{prev}}}{\\Delta t} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial p}{\\partial x} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial}{\\partial x}\\!\\left( \\frac{\\overline{j_x}^2}{\\overline{\\rho}} \\right)\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial x}\\, \\frac{\\overline{j_x}^2}{\\overline{\\rho}} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial}{\\partial y}\\!\\left( \\frac{\\overline{j_x}\\,\\overline{j_y}}{\\overline{\\rho}} \\right)\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial y}\\, \\frac{\\overline{j_x}\\,\\overline{j_y}}{\\overline{\\rho}} \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{\\partial \\overline{\\tau_{xx}}}{\\partial x}\n",
    "+ \\frac{1}{h} \\frac{\\partial h}{\\partial x}\\, \\left( \\overline{\\tau_{xx}} - \\tau_{xx}\\vert_{z=h_2} \\right) \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{\\partial \\overline{\\tau_{xy}}}{\\partial y} \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{1}{h}\\, \\tau_{xz}\\Big\\vert^{z=h_2}_{z=h_1} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial t}\\, \\overline{j_x}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q43wdjotj18",
   "metadata": {},
   "source": [
    "- **R2Tx**: Time derivative\n",
    "- **R21x**: Pressure gradient\n",
    "- **R22xx**, **R22xxS**: Momentum flux $j_x j_x$ + height source\n",
    "- **R22yx**, **R22yxS**: Momentum flux $j_x j_y$ + height source\n",
    "- **R23x**, **R23xS**: Normal stress $\\tau_{xx}$ + height source (not implemented)\n",
    "- **R23xy**: In-plane shear stress $\\tau_{xy}$ (simplified: $\\eta \\, \\partial u / \\partial y$)\n",
    "- **R24x**: Wall shear stress $\\tau_{xz}$\n",
    "- **R25x**: Height change over time (not implemented)\n",
    "- **R2Stabx**: Momentum stabilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vfiv87878to",
   "metadata": {},
   "source": [
    "## Momentum y\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 &= \n",
    "- \\frac{\\overline{j_y} - \\overline{j_y}_{\\mathrm{prev}}}{\\Delta t} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial p}{\\partial y} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial}{\\partial x}\\!\\left( \\frac{\\overline{j_x}\\,\\overline{j_y}}{\\overline{\\rho}} \\right)\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial x}\\, \\frac{\\overline{j_x}\\,\\overline{j_y}}{\\overline{\\rho}} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{\\partial}{\\partial y}\\!\\left( \\frac{\\overline{j_y}^2}{\\overline{\\rho}} \\right)\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial y}\\, \\frac{\\overline{j_y}^2}{\\overline{\\rho}} \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{\\partial \\overline{\\tau_{xy}}}{\\partial x} \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{\\partial \\overline{\\tau_{yy}}}{\\partial y}\n",
    "+ \\frac{1}{h} \\frac{\\partial h}{\\partial y}\\, \\left( \\overline{\\tau_{yy}} - \\tau_{yy}\\vert_{z=h_2} \\right) \\\\[2pt]\n",
    "&\\quad\n",
    "+ \\frac{1}{h}\\, \\tau_{yz}\\Big\\vert^{z=h_2}_{z=h_1} \\\\[2pt]\n",
    "&\\quad\n",
    "- \\frac{1}{h} \\frac{\\partial h}{\\partial t}\\, \\overline{j_y}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p25b1knssq9",
   "metadata": {},
   "source": [
    "- **R2Ty**: Time derivative\n",
    "- **R21y**: Pressure gradient\n",
    "- **R22xy**, **R22xyS**: Momentum flux $j_x j_y$ + height source\n",
    "- **R22yy**, **R22yyS**: Momentum flux $j_y j_y$ + height source\n",
    "- **R23yx**: In-plane shear stress $\\tau_{xy}$ (simplified: $\\eta \\, \\partial v / \\partial x$)\n",
    "- **R23y**, **R23yS**: Normal stress $\\tau_{yy}$ + height source (not implemented)\n",
    "- **R24y**: Wall shear stress $\\tau_{yz}$\n",
    "- **R25y**: Height change over time (not implemented)\n",
    "- **R2Staby**: Momentum stabilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d841grjfk",
   "metadata": {},
   "source": [
    "## Energy\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 &= \n",
    "-\\,\\frac{\\overline{E} - \\overline{E}_{\\text{prev}}}{\\Delta t} \\\\[6pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial (\\overline{E}\\, \\overline{u})}{\\partial x}\n",
    "- \\overline{E}\\, \\overline{u}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial x} \\\\[6pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial (\\overline{E}\\, \\overline{v})}{\\partial y}\n",
    "- \\overline{E}\\, \\overline{v}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial y} \\\\[6pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial (p\\,\\overline{u})}{\\partial x}\n",
    "- p\\,\\overline{u}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial x} \\\\[6pt]\n",
    "&\\quad\n",
    "-\\,\\frac{\\partial (p\\,\\overline{v})}{\\partial y}\n",
    "- p\\,\\overline{v}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial y} \\\\[6pt]\n",
    "&\\quad\n",
    "+\\,\\frac{\\partial}{\\partial x}\\!\\left(\\overline{\\tau_{xx}}\\,\\overline{u}\\right)\n",
    "+ \\left(\\overline{\\tau_{xx}}\\,\\overline{u}\\right)\\frac{1}{h}\\,\\frac{\\partial h}{\\partial x} \\\\[6pt]\n",
    "&\\quad\n",
    "+\\,\\frac{\\partial}{\\partial y}\\!\\left(\\overline{\\tau_{yy}}\\,\\overline{v}\\right)\n",
    "+ \\left(\\overline{\\tau_{yy}}\\,\\overline{v}\\right)\\frac{1}{h}\\,\\frac{\\partial h}{\\partial y} \\\\[6pt]\n",
    "&\\quad\n",
    "-\\,\\frac{1}{h}\\left(\\tau_{xz,\\text{bot}}\\,U + \\tau_{yz,\\text{bot}}\\,V\\right) \\\\[6pt]\n",
    "&\\quad\n",
    "+\\,k\\,\\left( \\frac{\\partial^2 \\overline{T}}{\\partial x^2} + \\frac{\\partial^2 \\overline{T}}{\\partial y^2} \\right) \\\\[6pt]\n",
    "&\\quad\n",
    "+ S_{\\text{walls}} \\\\[6pt]\n",
    "&\\quad\n",
    "- \\overline{E}\\,\\frac{1}{h}\\,\\frac{\\partial h}{\\partial t}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u2p965od3db",
   "metadata": {},
   "source": [
    "- **R3T**: Time derivative\n",
    "- **R31x**, **R31Sx**: Energy advection in x + height source\n",
    "- **R31y**, **R31Sy**: Energy advection in y + height source\n",
    "- **R32x**, **R32Sx**: Pressure work in x + height source\n",
    "- **R32y**, **R32Sy**: Pressure work in y + height source\n",
    "- **R33x**: Shear work $\\tau_{xx}$ in x + height source\n",
    "- **R33y**: Shear work $\\tau_{yy}$ in y + height source\n",
    "- **R34**: Wall shear work (combines x and y wall velocities)\n",
    "- **R35x**, **R35y**: Thermal diffusion in x and y\n",
    "- **R36**: Wall heat balance [see theory](./10_wall_heat.ipynb)\n",
    "- **R37**: Height change over time"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
